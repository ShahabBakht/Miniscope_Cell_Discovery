{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### load synth data\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from synthetic_data import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from synthetic_data import LorenzSystem, EmbeddedLowDNetwork\n",
    "\n",
    "        \n",
    "    \n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "lorenz = LorenzSystem(num_inits= 35,\n",
    "                        dt= 0.015)\n",
    "        \n",
    "net = EmbeddedLowDNetwork(low_d_system = lorenz,\n",
    "                            net_size = 5,\n",
    "                            base_rate = 1.0,\n",
    "                            dt = 0.015)\n",
    "        \n",
    "print('lorenz generated')\n",
    "\n",
    "generator = SyntheticCalciumDataGenerator(system     = net,\n",
    "                                            seed       = 750,\n",
    "                                            trainp     = 0.8,\n",
    "                                            burn_steps = 0,\n",
    "                                            num_steps  = 10,\n",
    "                                            num_trials = 10,\n",
    "                                            tau_cal    = 0.3,\n",
    "                                            dt_cal     = 0.05,\n",
    "                                            sigma      = 0.2,\n",
    "                                            frame_width= 64, \n",
    "                                            frame_height=64)\n",
    "\n",
    "data_dict = generator.generate_dataset()\n",
    "print('calcium data generated')\n",
    "\n",
    "# save_data_name = '/home/mila/b/bakhtias/Project-Codes/hierarchical_lfads/synth_data/lorenz_750'\n",
    "# with h5py.File(save_data_name, 'r') as hf:\n",
    "#     data_dict = {k: np.array(v) for k, v in hf.items()}\n",
    "# print(data_dict.keys())\n",
    "\n",
    "\n",
    "\n",
    "train_dl    = torch.utils.data.DataLoader(SyntheticCalciumVideoDataset(traces= data_dict['train_fluor'], cells=data_dict['cells'], device='cuda'), batch_size=10)\n",
    "valid_dl    = torch.utils.data.DataLoader(SyntheticCalciumVideoDataset(traces= data_dict['valid_fluor'], cells=data_dict['cells'], device='cuda'), batch_size=10)\n",
    "\n",
    "print('data loader built')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miniscope dataloader\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import tempfile\n",
    "from torchvision import transforms\n",
    "from utils.augmentations import Normalize\n",
    "\n",
    "class MiniscopeDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    \n",
    "    def __init__(self, device='cpu', num_workers= 1, tmpdir='/tmp/'):\n",
    "        \n",
    "        super(MiniscopeDataset, self).__init__()\n",
    "            \n",
    "        self.device = device\n",
    "        animal_id = 'A0634-201124'\n",
    "        data_dir = '/Users/shahab/Mila/Data/Miniscope/'\n",
    "        \n",
    "        \n",
    "        file_name = os.path.join(data_dir,animal_id,f'{animal_id}_raw.avi')\n",
    "        cap = cv2.VideoCapture(file_name)\n",
    "        frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        temporal_downsample_rate = 5\n",
    "        self.height = 64\n",
    "        self.width = 64\n",
    "        h_min, h_max = (78,142)\n",
    "        w_min, w_max = (133,197)\n",
    "        assert h_max - h_min == self.height\n",
    "        assert w_max - w_min == self.width\n",
    "        self.block_len = 10\n",
    "#         frameCount = 10000\n",
    "        self.transform = Normalize(110.8592,16.5243)\n",
    "        self.tempfile = tempfile.TemporaryFile(suffix='.dat', dir='/tmp')\n",
    "        self.tensors = (np.memmap(self.tempfile, dtype='float32', mode='w+',shape=(frameCount//self.block_len, 1, self.block_len, self.height, self.width)) )\n",
    "        fc_inblock = 0\n",
    "        bc = 0\n",
    "        for fc in range(frameCount//self.block_len * self.block_len):\n",
    "            ret, temp = cap.read()\n",
    "            self.tensors[bc,0,fc_inblock,:,:] = np.expand_dims(temp[h_min:h_max,w_min:w_max,0],0)\n",
    "            fc_inblock += 1\n",
    "            if fc_inblock == self.block_len:\n",
    "                fc_inblock = 0\n",
    "                bc += 1\n",
    "                \n",
    "            \n",
    "        del temp\n",
    "            \n",
    "        self.dtype = self[0][0].dtype\n",
    "        \n",
    "    def __getitem__(self, ix):\n",
    "        \n",
    "        temp = [torch.from_numpy(np.expand_dims(self.tensors[ix,0,i,:,:],0)) for i in range(self.block_len)]\n",
    "        temp = self.transform(temp)\n",
    "        T = torch.stack(temp).transpose(0,1)\n",
    "        return (T.to(self.device), ) #\n",
    "#         return (self.transform(torch.from_numpy(self.tensors[ix])).to(self.device), ) #\n",
    "    \n",
    "    def __len__(self):\n",
    "        # return traces.__len__()\n",
    "        return len(self.tensors)\n",
    "    \n",
    "    def close(self):\n",
    "        self.tempfile.close()\n",
    "        del self.tensors\n",
    "\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "mindata = MiniscopeDataset()\n",
    "batch_size = 100\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 40\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(mindata)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(mindata, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "valid_dl = torch.utils.data.DataLoader(mindata, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n",
      "torch.Size([100, 1, 10, 64, 64])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c6cd1ead36c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DeepMouse/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DeepMouse/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DeepMouse/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DeepMouse/lib/python3.7/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DeepMouse/lib/python3.7/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandperm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for k, v in enumerate(train_dl):\n",
    "    print(v[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train slot-attention autoencoder from scratch\n",
    "\n",
    "import os\n",
    "from autoencoder_slot_attention import AE_SlotAttention\n",
    "from scheduler import GradualWarmupScheduler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "args = {'exp_id': 2021021201,\n",
    "        'miniscope': True,\n",
    "        'batch_size': 100,\n",
    "        'lr': 0.0001,\n",
    "        'steplr_step_size': 50,\n",
    "        'steplr_gamma': 0.9,\n",
    "        'warmup_multiplier': 1.0,\n",
    "        'warmup_total_epoch': 1,\n",
    "        'num_epochs': 1500,\n",
    "        'out_conv_channels':64,\n",
    "        'input_dim': 64,\n",
    "        'num_slots': 20,\n",
    "        'slot_iter': 10,\n",
    "        'slot_hidden_dim': 64,\n",
    "        'img_save_freq': 20,\n",
    "        'noise_sigma': 0\n",
    "       }\n",
    "\n",
    "save_root_path = '/network/tmp1/bakhtias/Results/LFADS/slot-attention'\n",
    "checkpoint_file_name = os.path.join(save_root_path,f'{args[\"exp_id\"]}.pth.tar')\n",
    "\n",
    "\n",
    "model = AE_SlotAttention(out_conv_channels = args['out_conv_channels'], \n",
    "                             input_dim = args['input_dim'], \n",
    "                             num_slots = args['num_slots'], \n",
    "                             slot_iter = args['slot_iter'], \n",
    "                             slot_hidden_dim = args['slot_hidden_dim'], \n",
    "                             device = 'cuda').to('cuda')\n",
    "\n",
    "run = wandb.init(f\"slot-attention-test\",config=args)\n",
    "wandb.watch(model, log='all')\n",
    "print('\\n===========Check Grad============')\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)\n",
    "print('=================================\\n')\n",
    "\n",
    "num_epochs = args['num_epochs']  \n",
    "\n",
    "params = model.parameters()\n",
    "optimizer = optim.Adam(params, lr=args['lr'], weight_decay=1e-5)\n",
    "\n",
    "scheduler_steplr = StepLR(optimizer, step_size=args['steplr_step_size'], gamma=args['steplr_gamma'])\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=args['warmup_multiplier'], total_epoch=args['warmup_total_epoch'], after_scheduler=scheduler_steplr)\n",
    "\n",
    "global iteration; iteration = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    MSE = 0\n",
    "    count_tr = 0\n",
    "    model.train()\n",
    "    for idx, x in enumerate(tqdm(train_dl)):\n",
    "            if args['miniscope']:\n",
    "                x_in = x[0]\n",
    "            else:\n",
    "                x_in = x[0].permute(0,2,1,3,4)\n",
    "                b,t,c,w,h = x_in.shape\n",
    "                x_in = x_in.reshape(b*t,c,w,h)\n",
    "                \n",
    "            x_in = x_in + args['noise_sigma']*torch.randn(x_in.shape,requires_grad = False, device='cuda')\n",
    "            x_in = x_in - x_in[:].min()\n",
    "            x_out, _ = model(x_in)\n",
    "            mse = torch.nn.functional.mse_loss(x_out, x_in, reduction='sum')/x_in.shape[0]\n",
    "            optimizer.zero_grad()\n",
    "            mse.backward()\n",
    "            optimizer.step()\n",
    "            iteration += 1\n",
    "            \n",
    "            MSE += mse\n",
    "            count_tr += 1\n",
    "            del mse\n",
    "            \n",
    "            \n",
    "            \n",
    "    MSE_val = 0        \n",
    "    count_val = 0 \n",
    "    which_sample_vis, which_idx = 0, 0\n",
    "    if epoch % args['img_save_freq'] == 0:\n",
    "        fig, axs = plt.subplots(1,args['num_slots'])\n",
    "    model.eval()\n",
    "    with torch.no_grad(): \n",
    "        for idx, x in enumerate(tqdm(valid_dl)):\n",
    "                if args['miniscope']:\n",
    "                    x_in = x[0]\n",
    "                else:\n",
    "                    x_in = x[0].permute(0,2,1,3,4)\n",
    "                    b,t,c,w,h = x_in.shape\n",
    "                    x_in = x_in.reshape(b*t,c,w,h)\n",
    "                x_in = x_in - x_in[:].min()\n",
    "                x_out, mask = model(x_in)\n",
    "                mse_val = torch.nn.functional.mse_loss(x_out, x_in, reduction='sum')/x_in.shape[0]\n",
    "\n",
    "                MSE_val += mse_val\n",
    "                count_val += 1\n",
    "                \n",
    "                if (epoch % args['img_save_freq'] == 0) and (idx == which_idx):\n",
    "                    for k in range(args['num_slots']):\n",
    "                        axs[k].imshow(mask[which_sample_vis,k,:,:].cpu().numpy(),cmap='gray')\n",
    "                        plt.axis('off')\n",
    "                        \n",
    "    if epoch % args['img_save_freq'] == 0:\n",
    "        wandb.log({\"slots\":wandb.Image(fig) })\n",
    "        plt.close()\n",
    "                \n",
    "    # save checkpoint            \n",
    "    if epoch == 0:\n",
    "        best_MSE = MSE_val\n",
    "        torch.save({'epoch': epoch+1,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'best_MSE': best_MSE,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'iteration': iteration}, checkpoint_file_name)\n",
    "    else:\n",
    "        if MSE_val < best_MSE:\n",
    "            best_MSE = MSE_val\n",
    "            torch.save({'epoch': epoch+1,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'best_MSE': best_MSE,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'iteration': iteration}, checkpoint_file_name)\n",
    "    \n",
    "            \n",
    "    wandb.log({\"epoch\": epoch, \n",
    "                \"train loss\": MSE/count_tr,\n",
    "               \"val loss\": MSE_val/count_val,\n",
    "               \"last_lr\": scheduler_warmup.get_last_lr()[0]\n",
    "                })\n",
    "    \n",
    "    \n",
    "    scheduler_warmup.step(epoch)\n",
    "    print(f'Epoch: {epoch}    MSE_train: {MSE/count_tr:.2f}    MSE_val: {MSE_val/count_val: .2f}    last_lr:{scheduler_warmup.get_last_lr()[0]}')\n",
    "    \n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize results on val data\n",
    "\n",
    "import os\n",
    "from autoencoder_slot_attention import AE_SlotAttention\n",
    "from scheduler import GradualWarmupScheduler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "args = {'exp_id': 2021021101,\n",
    "        'miniscope': True,\n",
    "        'batch_size': 100,\n",
    "        'lr': 0.00004,\n",
    "        'steplr_step_size': 50,\n",
    "        'steplr_gamma': 0.9,\n",
    "        'warmup_multiplier': 1.0,\n",
    "        'warmup_total_epoch': 10,\n",
    "        'num_epochs': 1500,\n",
    "        'out_conv_channels':64,\n",
    "        'input_dim': 64,\n",
    "        'num_slots':20,\n",
    "        'slot_iter': 10,\n",
    "        'slot_hidden_dim': 64,\n",
    "        'img_save_freq': 20,\n",
    "        'noise_sigma': 0\n",
    "       }\n",
    "\n",
    "save_root_path = '/network/tmp1/bakhtias/Results/LFADS/slot-attention'\n",
    "checkpoint_file_name = os.path.join(save_root_path,f'{args[\"exp_id\"]}.pth.tar')\n",
    "\n",
    "model = AE_SlotAttention(out_conv_channels = args['out_conv_channels'], \n",
    "                             input_dim = args['input_dim'], \n",
    "                             num_slots = args['num_slots'], \n",
    "                             slot_iter = args['slot_iter'], \n",
    "                             slot_hidden_dim = args['slot_hidden_dim'], \n",
    "                             device = 'cuda').to('cuda')\n",
    "\n",
    "checkpoint = torch.load(checkpoint_file_name, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "which_sample_vis, which_idx = 35, 0\n",
    "model.eval()\n",
    "with torch.no_grad(): \n",
    "    for idx, x in enumerate(valid_dl):\n",
    "            if args['miniscope']:\n",
    "                x_in = x[0]\n",
    "            else:\n",
    "                x_in = x[0].permute(0,2,1,3,4)\n",
    "                b,t,c,w,h = x_in.shape\n",
    "                x_in = x_in.reshape(b*t,c,w,h)\n",
    "            x_in = x_in + args['noise_sigma']*torch.randn(x_in.shape,requires_grad = False, device='cuda')\n",
    "            x_in = x_in - x_in[:].min()\n",
    "            x_out, mask = model(x_in)\n",
    "            mse = torch.nn.functional.mse_loss(x_out, x_in, reduction='sum')/x_in.shape[0]\n",
    "#             fig, axs = plt.subplots(1,args['num_slots'])\n",
    "            for k in range(args['num_slots']):\n",
    "                    \n",
    "                plt.imshow(mask[0,k,:,:].cpu().numpy(),cmap='gray')#axs[k].imshow(mask[which_sample_vis,k,:,:].cpu().numpy())#\n",
    "                plt.colorbar()\n",
    "                plt.show()\n",
    "            print(x_in[which_sample_vis,0,:,:].std())\n",
    "            plt.imshow(x_out[which_sample_vis,0,:,:].cpu().numpy(),cmap='gray')\n",
    "#             plt.clim((0,2))\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "            plt.imshow(x_in[which_sample_vis,0,:,:].cpu().numpy(),cmap='gray')\n",
    "#             plt.clim((0,2))\n",
    "            plt.colorbar()\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tune slot-attention module on a new dataset\n",
    "\n",
    "import os\n",
    "from autoencoder_slot_attention import AE_SlotAttention\n",
    "from scheduler import GradualWarmupScheduler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "\n",
    "args = {'exp_id': 2021021101,\n",
    "        'miniscope': True,\n",
    "        'batch_size': 10,\n",
    "        'lr': 0.00004,\n",
    "        'steplr_step_size': 50,\n",
    "        'steplr_gamma': 0.9,\n",
    "        'warmup_multiplier': 1.0,\n",
    "        'warmup_total_epoch': 10,\n",
    "        'num_epochs': 1500,\n",
    "        'out_conv_channels':64,\n",
    "        'input_dim': 64,\n",
    "        'num_slots': 10,\n",
    "        'slot_iter': 10,\n",
    "        'slot_hidden_dim': 64,\n",
    "        'img_save_freq': 20,\n",
    "        'noise_sigma': 0,\n",
    "        'pretrained': 2021020101\n",
    "       }\n",
    "\n",
    "\n",
    "save_root_path = '/network/tmp1/bakhtias/Results/LFADS/slot-attention'\n",
    "checkpoint_file_name = os.path.join(save_root_path,f'{args[\"exp_id\"]}.pth.tar')\n",
    "pretrained_checkpoint_file_name = os.path.join(save_root_path,f'{args[\"pretrained\"]}.pth.tar')\n",
    "\n",
    "model = AE_SlotAttention(out_conv_channels = args['out_conv_channels'], \n",
    "                             input_dim = args['input_dim'], \n",
    "                             num_slots = args['num_slots'], \n",
    "                             slot_iter = args['slot_iter'], \n",
    "                             slot_hidden_dim = args['slot_hidden_dim'], \n",
    "                             device = 'cuda').to('cuda')\n",
    "\n",
    "checkpoint = torch.load(pretrained_checkpoint_file_name, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "run = wandb.init(f\"slot-attention-test\",config=args)\n",
    "wandb.watch(model, log='all')\n",
    "\n",
    "print('\\n===========Check Grad============')\n",
    "for name, param in model.named_parameters():\n",
    "    if ('slot' not in name) and ('pos_embed' not in name):\n",
    "        param.requires_grad = False\n",
    "    print(name, param.requires_grad)\n",
    "print('=================================\\n')\n",
    "    \n",
    "num_epochs = args['num_epochs']  \n",
    "    \n",
    "params = model.parameters()\n",
    "optimizer = optim.Adam(params, lr=args['lr'], weight_decay=1e-5)\n",
    "\n",
    "scheduler_steplr = StepLR(optimizer, step_size=args['steplr_step_size'], gamma=args['steplr_gamma'])\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=args['warmup_multiplier'], total_epoch=args['warmup_total_epoch'], after_scheduler=scheduler_steplr)\n",
    "\n",
    "global iteration; iteration = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    MSE = 0\n",
    "    count_tr = 0\n",
    "    model.train()\n",
    "    for idx, x in enumerate(train_dl):\n",
    "            if args['miniscope']:\n",
    "                x_in = x[0]\n",
    "            else:\n",
    "                x_in = x[0].permute(0,2,1,3,4)\n",
    "                b,t,c,w,h = x_in.shape\n",
    "                x_in = x_in.reshape(b*t,c,w,h)\n",
    "            x_in = x_in + args['noise_sigma']*torch.randn(x_in.shape,requires_grad = False, device='cuda')\n",
    "            x_in = x_in - x_in[:].min()\n",
    "            x_out, _ = model(x_in)\n",
    "            mse = torch.nn.functional.mse_loss(x_out, x_in, reduction='sum')/x_in.shape[0]\n",
    "            optimizer.zero_grad()\n",
    "            mse.backward()\n",
    "            optimizer.step()\n",
    "            iteration += 1\n",
    "            \n",
    "            MSE += mse\n",
    "            count_tr += 1\n",
    "            del mse\n",
    "            \n",
    "            \n",
    "            \n",
    "    MSE_val = 0        \n",
    "    count_val = 0 \n",
    "    which_sample_vis = 35\n",
    "    if epoch % args['img_save_freq'] == 0:\n",
    "        fig, axs = plt.subplots(len(valid_dl),args['num_slots'])\n",
    "    model.eval()\n",
    "    with torch.no_grad(): \n",
    "        for idx, x in enumerate(valid_dl):\n",
    "                if args['miniscope']:\n",
    "                    x_in = x[0]\n",
    "                else:\n",
    "                    x_in = x[0].permute(0,2,1,3,4)\n",
    "                    b,t,c,w,h = x_in.shape\n",
    "                    x_in = x_in.reshape(b*t,c,w,h)\n",
    "                x_in = x_in - x_in[:].min()\n",
    "                x_out, mask = model(x_in)\n",
    "                mse_val = torch.nn.functional.mse_loss(x_out, x_in, reduction='sum')/x_in.shape[0]\n",
    "\n",
    "                MSE_val += mse_val\n",
    "                count_val += 1\n",
    "                \n",
    "                if epoch % args['img_save_freq'] == 0:\n",
    "                    for k in range(args['num_slots']):\n",
    "                        axs[idx,k].imshow(mask[which_sample_vis,k,:,:].cpu().numpy(),cmap='gray')\n",
    "                        plt.axis('off')\n",
    "                        \n",
    "    if epoch % args['img_save_freq'] == 0:\n",
    "        wandb.log({\"slots\":wandb.Image(fig) })\n",
    "        plt.close()\n",
    "                \n",
    "    # save checkpoint            \n",
    "    if epoch == 0:\n",
    "        best_MSE = MSE_val\n",
    "        torch.save({'epoch': epoch+1,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'best_MSE': best_MSE,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'iteration': iteration}, checkpoint_file_name)\n",
    "    else:\n",
    "        if MSE_val < best_MSE:\n",
    "            best_MSE = MSE_val\n",
    "            torch.save({'epoch': epoch+1,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'best_MSE': best_MSE,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'iteration': iteration}, checkpoint_file_name)\n",
    "    \n",
    "            \n",
    "    wandb.log({\"epoch\": epoch, \n",
    "                \"train loss\": MSE/count_tr,\n",
    "               \"val loss\": MSE_val/count_val,\n",
    "               \"last_lr\": scheduler_warmup.get_last_lr()[0]\n",
    "                })\n",
    "    \n",
    "    \n",
    "    scheduler_warmup.step(epoch)\n",
    "    print(f'Epoch: {epoch}    MSE_train: {MSE/count_tr:.2f}    MSE_val: {MSE_val/count_val: .2f}    last_lr:{scheduler_warmup.get_last_lr()[0]}')\n",
    "    \n",
    "run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.randn((50,10, 1024, 32))\n",
    "xt = x[:,0,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1024, 32])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
